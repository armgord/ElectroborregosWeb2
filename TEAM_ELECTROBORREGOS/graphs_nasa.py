import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import re
import os
import sys

# --- CONFIGURACI√ìN GENERAL Y DE ESTILO ---
# El directorio de salida es AHORA SIMPLEMENTE "graficos" (local)
OUTPUT_DIR_NAME = "graficos"
PALETTE = "viridis" 

BEAUTIFUL_NAMES = {
    'plant_biology': 'Biolog√≠a Vegetal', 'radiation_biology': 'Biolog√≠a de la Radiaci√≥n',
    'cell_and_developmental_biology': 'Biolog√≠a Celular y del Desarrollo', 'cardiovascular_system': 'Sistema Cardiovascular',
    'comparative_biology_and_model_organisms': 'Biolog√≠a Comparativa y Organismos Modelo', 'genomics_and_multi_omics': 'Gen√≥mica y Multi-√≥mica',
    'immunology': 'Inmunolog√≠a', 'microbiology_and_microbiome': 'Microbiolog√≠a y Microbioma',
    'microgravity_and_environment': 'Microgravedad y Ambiente', 'musculoskeletal_system': 'Sistema Musculoesquel√©tico',
    'other': 'Otra', 'unknown': 'Desconocida', 'bone_health': 'Salud √ìsea', 'muscle_health': 'Salud Muscular',
    'neuroscience': 'Neurociencia', 'immune_system': 'Sistema Inmune', 'microgravity_effects': 'Efectos de la Microgravedad',
    'genomics_proteomics': 'Gen√≥mica y Prote√≥mica', 'microbiome': 'Microbioma', 'cell_biology': 'Biolog√≠a Celular',
    'human_factors': 'Factores Humanos', 'method_development': 'Desarrollo de M√©todos'
}


# --- FUNCI√ìN PRINCIPAL DE CARGA Y LIMPIEZA DE DATOS ---
def load_and_clean_data(filename="nasa_articles.csv"):
    """Carga el CSV asumiendo que est√° en el mismo directorio que el script."""
    
    # 1. Determina la ruta del directorio del script actual (necesario para el CSV)
    script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))
    filepath = os.path.join(script_dir, filename)

    try:
        df = pd.read_csv(filepath)
        print("‚úÖ Archivo CSV cargado exitosamente desde:", filepath)
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo '{filename}' en la ruta: {filepath}")
        return None
        
    # 2. Limpieza de datos (tu c√≥digo original)
    df['year'] = pd.to_numeric(df['year'], errors='coerce')
    df.dropna(subset=['year'], inplace=True)
    df['year'] = df['year'].astype(int)
    df = df[df['research_area'].notna() & ~df['research_area'].isin(['Error', 'unclassified'])].copy()
    df['research_area'] = df['research_area'].map(BEAUTIFUL_NAMES).fillna(df['research_area'])
    
    return df

# --- FUNCIONES PARA GENERAR CADA GR√ÅFICO (Se mantuvieron sin cambios mayores) ---

def plot_research_area_distribution(df, output_dir):
    print("üìä Generando Gr√°fico 1: Distribuci√≥n de √Åreas...")
    plt.figure(figsize=(12, 8))
    area_counts = df['research_area'].value_counts()
    sns.barplot(x=area_counts.index, y=area_counts.values, palette=PALETTE)
    plt.title('Distribuci√≥n de Art√≠culos por √Årea de Investigaci√≥n', fontsize=16, weight='bold')
    plt.xlabel('√Årea de Investigaci√≥n', fontsize=12); plt.ylabel('N√∫mero de Art√≠culos', fontsize=12)
    plt.xticks(rotation=45, ha='right'); plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "1_distribucion_areas.png"), dpi=300); plt.close()

def plot_publications_over_time(df, output_dir):
    print("üìà Generando Gr√°fico 2: Publicaciones en el Tiempo...")
    plt.figure(figsize=(12, 6))
    year_counts = df['year'].value_counts().sort_index()
    year_counts = year_counts[year_counts.index > 1990]
    sns.lineplot(x=year_counts.index, y=year_counts.values, marker='o', color=sns.color_palette(PALETTE, 1)[0])
    plt.title('Volumen de Publicaciones por A√±o', fontsize=16, weight='bold')
    plt.xlabel('A√±o de Publicaci√≥n', fontsize=12); plt.ylabel('N√∫mero de Art√≠culos', fontsize=12)
    plt.grid(True, which='both', linestyle='--', linewidth=0.5); plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "2_publicaciones_por_a√±o.png"), dpi=300); plt.close()

def plot_top_keywords(df, output_dir, top_n=25):
    print("‚òÅÔ∏è Generando Gr√°fico 3: Palabras Clave Frecuentes...")
    keywords = df['keywords'].dropna().str.lower()
    stop_words = ['keywords', 'key words', 'no encontradas', 'introduction', 'results', 'conclusions', 'methods']
    all_words = [word.strip() for text in keywords for word in re.split(r'[;,]', text) if word.strip() and word.strip() not in stop_words and len(word.strip()) > 2]
    word_counts = Counter(all_words)
    if not word_counts: return

    wc = WordCloud(width=1200, height=600, background_color='white', colormap=PALETTE).generate_from_frequencies(word_counts)
    plt.figure(figsize=(15, 7)); plt.imshow(wc, interpolation='bilinear'); plt.axis('off'); plt.title('Nube de Palabras Clave', fontsize=16, weight='bold'); plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "3a_nube_keywords.png"), dpi=300); plt.close()

    df_keywords = pd.DataFrame(word_counts.most_common(top_n), columns=['Keyword', 'Frecuencia'])
    plt.figure(figsize=(12, 10)); sns.barplot(x='Frecuencia', y='Keyword', data=df_keywords, palette=PALETTE + "_r")
    plt.title(f'Top {top_n} Palabras Clave', fontsize=16, weight='bold'); plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "3b_barras_keywords.png"), dpi=300); plt.close()

def plot_area_evolution(df, output_dir, top_n=7):
    print("‚è≥ Generando Gr√°fico 4: Evoluci√≥n de √Åreas...")
    top_areas = df['research_area'].value_counts().nlargest(top_n).index
    df_filtered = df[df['research_area'].isin(top_areas)]
    evolution_data = df_filtered.groupby(['year', 'research_area']).size().unstack(fill_value=0)
    if evolution_data.empty: return

    evolution_data.plot(kind='area', stacked=True, figsize=(15, 8), colormap=PALETTE)
    plt.title(f'Evoluci√≥n de las Top {top_n} √Åreas de Investigaci√≥n', fontsize=16, weight='bold')
    plt.xlabel('A√±o'); plt.ylabel('N√∫mero de Art√≠culos')
    plt.legend(title='√Årea de Investigaci√≥n', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout(rect=[0, 0, 0.85, 1]); plt.savefig(os.path.join(output_dir, "4_evolucion_areas.png"), dpi=300); plt.close('all')

def plot_top_authors(df, output_dir, top_n=20):
    print("üë©‚Äçüî¨ Generando Gr√°fico 5: Autores M√°s Prol√≠ficos...")
    authors = df['authors'].dropna().str.strip().str.lower(); authors = authors[authors != 'no encontrados']
    all_authors = [name.strip().title() for author_list in authors for name in author_list.split(',')]
    if not all_authors: return

    author_counts = Counter(all_authors)
    df_authors = pd.DataFrame(author_counts.most_common(top_n), columns=['Autor', 'Publicaciones'])
    plt.figure(figsize=(12, 10)); sns.barplot(x='Publicaciones', y='Autor', data=df_authors, palette=PALETTE + "_r")
    plt.title(f'Top {top_n} Autores con M√°s Publicaciones', fontsize=16, weight='bold'); plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "5_top_autores.png"), dpi=300); plt.close()

def plot_author_specialization_bubble_chart(df, output_dir, top_n_authors=15):
    """Genera un gr√°fico de burbujas que muestra la especializaci√≥n por autor y tema."""
    print("üîµ Generando Gr√°fico 6: Especializaci√≥n de Autores (Burbujas)...")
    
    author_topic_counts = []
    for _, row in df.iterrows():
        authors = [a.strip().title() for a in str(row['authors']).split(',') if a.strip()]
        for author in authors:
            author_topic_counts.append({'Author': author, 'Topic': row['research_area']})
            
    df_author_topic = pd.DataFrame(author_topic_counts)
    publications_by_author_topic = df_author_topic.groupby(['Author', 'Topic']).size().reset_index(name='Publications')
    
    top_authors = df_author_topic['Author'].value_counts().nlargest(top_n_authors).index
    publications_by_author_topic = publications_by_author_topic[publications_by_author_topic['Author'].isin(top_authors)]

    if publications_by_author_topic.empty:
        print("Advertencia: No hay suficientes datos para el Gr√°fico de Burbujas.")
        return

    plt.figure(figsize=(16, 10))
    sns.scatterplot(
        data=publications_by_author_topic,
        x='Author', y='Topic', size='Publications', 
        sizes=(100, 2000), 
        hue='Topic', 
        palette=PALETTE, 
        edgecolor='gray',
        alpha=0.8
    )
    plt.title(f'Especializaci√≥n de los Top {top_n_authors} Autores (Burbujas)', fontsize=18, weight='bold')
    plt.xlabel('Autor', fontsize=12); plt.ylabel('√Årea de Investigaci√≥n', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.legend(title='√Årea de Investigaci√≥n', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout(rect=[0, 0, 0.85, 1]); plt.savefig(os.path.join(output_dir, "6_especializacion_autores_burbujas.png"), dpi=300); plt.close()


# --- EJECUCI√ìN DEL SCRIPT ---
if __name__ == "__main__":
    
    # 1. Define la ruta de salida (simplemente la carpeta local)
    OUTPUT_DIR_PATH = "graficos" 

    if not os.path.exists(OUTPUT_DIR_PATH):
        try:
            os.makedirs(OUTPUT_DIR_PATH)
            print(f"üìÅ Directorio '{OUTPUT_DIR_PATH}' creado.")
        except Exception as e:
            print(f"‚ùå ERROR CR√çTICO al crear directorio. Verifique permisos: {e}")
            sys.exit(1)

    # 2. Carga de datos
    main_df = load_and_clean_data()
    
    # 3. Generaci√≥n de gr√°ficos
    if main_df is not None:
        plot_research_area_distribution(main_df, OUTPUT_DIR_PATH)
        plot_publications_over_time(main_df, OUTPUT_DIR_PATH)
        plot_top_keywords(main_df, OUTPUT_DIR_PATH)
        plot_area_evolution(main_df, OUTPUT_DIR_PATH)
        plot_top_authors(main_df, OUTPUT_DIR_PATH)
        plot_author_specialization_bubble_chart(main_df, OUTPUT_DIR_PATH)

        print("\nüéâ ¬°Todos los gr√°ficos han sido generados y guardados correctamente en:", OUTPUT_DIR_PATH, "!")